# LangChain Knowledge Assistant

A production-ready full-stack application for uploading documents, chatting with them, and retrieving intelligent answers. Built with **LangChain**, **FAISS**, **PostgreSQL**, **FastAPI**, and **React**.

## ğŸ§  Features

* ğŸ“„ Upload and parse multiple file types (PDF, DOCX, TXT, etc.)
* ğŸ’¬ Chat with documents using LangChain & OpenAI
* ğŸ” FAISS vector store for semantic search
* ğŸ—‚ï¸ PostgreSQL database for metadata and session history
* ğŸ§  Chat memory support
* âš¡ FastAPI backend
* ğŸ’» React frontend (Vite + Tailwind)
* ğŸ“¦ Dockerized for deployment
* ğŸ“ Modular and scalable architecture

---

## ğŸ“ Project Structure

```bash
langchain-knowledge-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Technologies

* **LangChain** â€“ for intelligent agent and chain management
* **OpenAI API** â€“ for embeddings & chat completion
* **FAISS** â€“ for fast vector similarity search
* **FastAPI** â€“ high-performance Python backend
* **PostgreSQL** â€“ for storing session and file metadata
* **React + Vite + Tailwind** â€“ for a fast, modern UI
* **Docker** â€“ for containerized deployment

---

## ğŸ” Environment Variables (.env)

See `.env.example`:

```env
OPENAI_API_KEY=your-openai-key
API_HOST=
API_PORT=
ENVIRONMENT=
APP_NAME=

POSTGRES_DB=
POSTGRES_USER=
POSTGRES_PASSWORD=
POSTGRES_HOST=
POSTGRES_PORT=
DATABASE_URL=

OPENAI_API_KEY=
OPENAI_API_BASE=
OPENAI_MODEL=

VECTOR_DB_TYPE=
VECTOR_STORE_PATH=

UPLOAD_DIR=

MEMORY_WINDOW_SIZE=

LOG_LEVEL=

```

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/FAS2024/langchain-knowledge-assistant.git
cd langchain-knowledge-assistant
```

### 2. Create `.env` Files

Copy `.env.example` and update values in `backend/.env`.

```bash
cp backend/.env.example backend/.env
```

### 3. Build and Run with Docker

```bash
docker-compose up --build
```

Backend: `http://localhost:8000`
Frontend: `http://localhost:3000`

---

## ğŸ§ª Running Tests (Coming Soon)

```bash
# backend tests
cd backend
pytest
```

---

## ğŸ“¦ Deployment

You can deploy using Docker to any cloud platform:

* Render
* Railway
* AWS/GCP/Azure

Set environment variables for production and use secure credentials.

---

## ğŸ§‘â€ğŸ’» Author

**Fatai Ayinla Sunmonu (FAS)**

* LinkedIn: [https://linkedin.com/in/fatai-sunmonu](https://linkedin.com/in/fatai-sunmonu)
* GitHub: [https://github.com/FAS2024](https://github.com/FAS2024)

---

## ğŸ“œ License

This project is licensed under the MIT License.